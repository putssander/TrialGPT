{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4ed7cef9-6979-40ab-b5be-de6c7178d183",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "source": [
    "# Dutch local-llm edition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d4266370-defd-42a5-b35f-7fc077f39252",
   "metadata": {},
   "source": [
    "This notebook is for a linux environment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb583150-ac3f-407d-94e0-8262a01c0d79",
   "metadata": {},
   "source": [
    "Setup\n",
    "1. Activate the kernel in terminal\n",
    "source /work/ml/TrialGPT/notebooks/myenv/bin/activate\n",
    "python -m ipykernel install --user --name=myenv --display-name \"Python (myenv)\"\n",
    "now select this kernel in the notebook\n",
    "\n",
    "\n",
    "fuser -k 8080/tcp\n",
    "\n",
    "2. setup ssh and tunnel gui\n",
    "\n",
    "ssh ucloud@ssh.cloud.sdu.dk -p 2290\n",
    "openwebui\n",
    "ssh -L 8080:localhost:8080 -p 2175 ucloud@ssh.cloud.sdu.dk\n",
    "ssh -L 3000:localhost:3000 -p 2290 ucloud@ssh.cloud.sdu.dk\n",
    "ssh -L 11434:localhost:11434 -p 2175 ucloud@ssh.cloud.sdu.dk\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd7c1df-96d0-4eab-a36e-b13d16788f25",
   "metadata": {},
   "source": [
    "### 1. Install Ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8b095c-e78e-4f3a-a7ed-917bf881d461",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "!curl -fsSL https://ollama.com/install.sh | sh"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "26bce8f3-801a-47cb-8996-ab689c369062",
   "metadata": {},
   "source": [
    "### 2. Run Ollama\n",
    "\n",
    "The following comments not be executed in this notebook, use the terminal instead"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e80aba36-15bc-4922-8188-3898d1261075",
   "metadata": {},
   "source": [
    "#### 2.1 Create Ollama model dir (New Terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ea90c9e-4b64-4b89-b3a1-c9f5b65d6706",
   "metadata": {},
   "outputs": [],
   "source": [
    "!mkdir /workspeech/models/ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3203d70-8815-44e9-b5d1-284d987c2f2e",
   "metadata": {},
   "source": [
    "#### 2.2 Set Ollama model dir as environment variable (Terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1ceaee6-73f4-4c8f-a19f-bd02ac5ed6ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "export OLLAMA_MODELS=\"/work/speech/models/ollama\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7acde5c-2d11-42d9-9e2b-a34cc3dceecc",
   "metadata": {},
   "source": [
    "#### 2.3 Run Ollama in  terminal (Terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8537592-87de-4731-841e-c073cb24d250",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama serve"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34a53ba1-2d7e-4c86-a030-851aca2d42d4",
   "metadata": {},
   "source": [
    "#### 2.4. Run Ollama model (New Terminal)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb76468b-8bfc-476d-857d-b50af5c4a2bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "ollama run llama3.3\n",
    "ollama run phi4"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae4de41d-c568-42fc-b26e-6d264576f971",
   "metadata": {},
   "source": [
    "#### 2.5 Verify models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07575c11-803f-42d2-b274-c57bc0612577",
   "metadata": {},
   "outputs": [],
   "source": [
    "! curl http://127.0.0.1:11434/v1/models  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d36550b-ffbe-4c2e-9d90-74eadc32f403",
   "metadata": {},
   "source": [
    "### 3 Prompt Ollama"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6866fab2-7e18-41ac-aff4-96fd6e7b9698",
   "metadata": {},
   "source": [
    "#### 3.1 Prompt using Ollama client"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f37953d-8e83-4509-9f81-b3f332300d82",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install ollama"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "10611c95-df8f-4cfa-b7ac-178a3380d86f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import ollama\n",
    "\n",
    "response = ollama.chat(\n",
    "    model='llama3.3:latest',\n",
    "    messages=[\n",
    "        {\n",
    "            'role': 'user',\n",
    "            'content': 'Why is the sky blue?',\n",
    "        },\n",
    "    ]\n",
    ")\n",
    "\n",
    "print(response['message']['content'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1d00603-c8b2-4ca0-b89c-1d5d7d2fbc58",
   "metadata": {},
   "source": [
    "#### 3.2 Prompt using AISuite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f5ed0e0-33b2-4623-97ef-d1ddff75e2d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install aisuite[all]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f01a8784-4ef2-46f1-b6cc-d5c9b46751a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "!export OPENAI_API_KEY=\"OLLAMA\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "447bf4ec-00aa-47b9-9f16-5b11b9c41a8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "client = ai.Client()\n",
    "\n",
    "models = [\"openai:gpt-4o\", \"anthropic:claude-3-5-sonnet-20240620\"]\n",
    "models = [\"ollama:llama3.3:latest\"]\n",
    "# models = [\"ollama:deepseek-r1:70b\"]\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Respond in Pirate English.\"},\n",
    "    {\"role\": \"user\", \"content\": \"Tell me a joke.\"},\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.75\n",
    "    )\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0443172e-3073-429a-b45c-ab744b3cc927",
   "metadata": {},
   "outputs": [],
   "source": [
    "import aisuite as ai\n",
    "client = ai.Client()\n",
    "\n",
    "models = [\"openai:gpt-4o\", \"anthropic:claude-3-5-sonnet-20240620\"]\n",
    "models = [\"ollama:llama3.3:latest\"]\n",
    "\n",
    "\n",
    "\n",
    "messages = [\n",
    "    {\"role\": \"system\", \"content\": \"Respond using internet access\"},\n",
    "    {\"role\": \"user\", \"content\": \"Summary of the latest news\"},\n",
    "]\n",
    "\n",
    "for model in models:\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=0.75\n",
    "    )\n",
    "    print(response.choices[0].message.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08b0689d-4413-45ce-aa24-a9d822c8a47d",
   "metadata": {},
   "source": [
    "## Install open-webui"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08437d16-3b91-44de-8147-e2b1a85c985f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install open-webui\n",
    "!pip install open-webui -U"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "640f5d96-696a-4d44-b58c-a76f2fbf6038",
   "metadata": {
    "editable": true,
    "slideshow": {
     "slide_type": ""
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# in termerminal \n",
    "# source myenv/bin/activate\n",
    "# open-webui serve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5085edec-d8ed-4fdf-b052-26386d08704e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "\n",
    "def chat_with_file(token, model, query, file_id):\n",
    "    url = 'http://localhost:3000/api/chat/completions'\n",
    "    headers = {\n",
    "        'Authorization': f'Bearer {token}',\n",
    "        'Content-Type': 'application/json'\n",
    "    }\n",
    "    payload = {\n",
    "        'model': model,\n",
    "        'messages': [{'role': 'user', 'content': query}],\n",
    "        'files': [{'type': 'file', 'id': file_id}]\n",
    "    }\n",
    "    response = requests.post(url, headers=headers, json=payload)\n",
    "    return response.json()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55943772-222b-4b43-acca-9db7ec150ce2",
   "metadata": {},
   "outputs": [],
   "source": [
    "!curl -H \"Authorization: Bearer eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9.eyJpZCI6ImNlY2Q0MjllLTlhYmYtNDEzNy04OTQzLTRjOTJjNzcyZjFmMSJ9.vCHkMVWC_bgIMJpR93SmNKcLAnzOCKFKJ_ZSPnOCtxQ\" http://localhost:8080/api/models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09b3291f-5f67-4fea-947a-25a6e97aa599",
   "metadata": {},
   "source": [
    "## Install Perplexica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "06ab0980-114b-46a2-b123-6a3b109ef9cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "!git clone https://github.com/ItzCrazyKns/Perplexica.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8211359f-42b6-413d-81dd-0fea00e1942b",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip show open-webui"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 ",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
